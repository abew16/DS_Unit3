
satisfaction_level - 
Level of satisfaction (0-1) - 
Numeric  
last_evaluation - 
1 - 
Numeric  
number_project - 
Number of projects completed while at work - 
Numeric  
average_montly_hours - 
Average monthly hours at workplace - 
Numeric  
time_spend_company - 
Number of years spent in the company - 
Numeric  
Work_accident - 
Whether the employee had a workplace accident - 
Numeric  
left - 
Whether the employee left the workplace or not (1 or 0) Factor - 
Numeric   
promotion_last_5years - 
Whether the employee was promoted in the last five years -
Numeric  
sales -
Department in which they work for -
String  
salary - 
Relative level of salary (high) -
String

Dataset Link:
https://www.kaggle.com/ludobenistant/hr-analytics


```python
import pandas as pd
import numpy as np
from sklearn import linear_model
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
```


```python
file = 'C:\\Users\\Abe\\Data Science Bootcamp\\Unit 3\\Advanced Regression\\Challenge\\HR_comma_sep.csv'
df = pd.read_csv(file)

# Getting Memory Error with all the data.
# df.sample(frac=.8,replace=True)
```


```python
df_objects = df.select_dtypes(include=['object'])
for col in df_objects.columns:
    print(col)
    print(df[col].unique())
```

    sales
    ['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'
     'product_mng' 'marketing' 'RandD']
    salary
    ['low' 'medium' 'high']
    


```python
Y = df['left']
X = df.drop(['left'],axis=1)
X = pd.get_dummies(X)
```


```python
#Vanilla Logistic Regression
#Use l2 regression and an extremely high value for C to (almost) remove the penalty
v_regr = linear_model.LogisticRegression(C=1e9,penalty='l2')

v_regr.fit(X,Y)
v_score = cross_val_score(v_regr,X,Y,cv=10)
print(v_score)
print(v_score.mean())
```

    [ 0.80746169  0.79066667  0.79466667  0.78666667  0.806       0.806
      0.79333333  0.788       0.74716478  0.73649099]
    0.785645079605
    


```python
#Ridge Regression
r_regr = linear_model.LogisticRegression(C=.5,penalty='l2')

r_regr.fit(X,Y)
r_score = cross_val_score(r_regr,X,Y,cv=10)
print(r_score)
print(r_score.mean())
```

    [ 0.80746169  0.78866667  0.79333333  0.78466667  0.804       0.804
      0.79133333  0.78933333  0.74382922  0.73315544]
    0.783977968198
    


```python
l_regr = linear_model.LogisticRegression(C=.5,penalty='l1')

l_regr.fit(X,Y)
l_score = cross_val_score(l_regr,X,Y,cv=10)
print(l_score)
print(l_score.mean())
```

    [ 0.80746169  0.79        0.79466667  0.78533333  0.804       0.80533333
      0.796       0.78933333  0.74649767  0.73649099]
    0.785511701798
    


```python
params = pd.DataFrame()

params['Features'] = X.columns
params['Vanilla'] = v_regr.coef_[0]
params['Ridge'] = r_regr.coef_[0]
params['Lasso'] = l_regr.coef_[0]
params
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Features</th>
      <th>Vanilla</th>
      <th>Ridge</th>
      <th>Lasso</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>satisfaction_level</td>
      <td>-4.117259</td>
      <td>-4.037027</td>
      <td>-4.108213</td>
    </tr>
    <tr>
      <th>1</th>
      <td>last_evaluation</td>
      <td>0.769927</td>
      <td>0.699809</td>
      <td>0.667461</td>
    </tr>
    <tr>
      <th>2</th>
      <td>number_project</td>
      <td>-0.314953</td>
      <td>-0.307126</td>
      <td>-0.309603</td>
    </tr>
    <tr>
      <th>3</th>
      <td>average_montly_hours</td>
      <td>0.004414</td>
      <td>0.004400</td>
      <td>0.004433</td>
    </tr>
    <tr>
      <th>4</th>
      <td>time_spend_company</td>
      <td>0.266324</td>
      <td>0.264342</td>
      <td>0.264730</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Work_accident</td>
      <td>-1.525651</td>
      <td>-1.498874</td>
      <td>-1.511743</td>
    </tr>
    <tr>
      <th>6</th>
      <td>promotion_last_5years</td>
      <td>-1.211156</td>
      <td>-1.129725</td>
      <td>-1.306843</td>
    </tr>
    <tr>
      <th>7</th>
      <td>sales_IT</td>
      <td>-0.106452</td>
      <td>-0.104998</td>
      <td>-0.146147</td>
    </tr>
    <tr>
      <th>8</th>
      <td>sales_RandD</td>
      <td>-0.506033</td>
      <td>-0.494244</td>
      <td>-0.537139</td>
    </tr>
    <tr>
      <th>9</th>
      <td>sales_accounting</td>
      <td>0.071539</td>
      <td>0.070394</td>
      <td>0.003339</td>
    </tr>
    <tr>
      <th>10</th>
      <td>sales_hr</td>
      <td>0.308447</td>
      <td>0.301667</td>
      <td>0.235168</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sales_management</td>
      <td>-0.377364</td>
      <td>-0.373419</td>
      <td>-0.400472</td>
    </tr>
    <tr>
      <th>12</th>
      <td>sales_marketing</td>
      <td>0.055890</td>
      <td>0.051464</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sales_product_mng</td>
      <td>-0.083291</td>
      <td>-0.082527</td>
      <td>-0.115172</td>
    </tr>
    <tr>
      <th>14</th>
      <td>sales_sales</td>
      <td>0.034198</td>
      <td>0.032766</td>
      <td>-0.014294</td>
    </tr>
    <tr>
      <th>15</th>
      <td>sales_support</td>
      <td>0.125110</td>
      <td>0.122021</td>
      <td>0.064892</td>
    </tr>
    <tr>
      <th>16</th>
      <td>sales_technical</td>
      <td>0.140080</td>
      <td>0.138372</td>
      <td>0.085857</td>
    </tr>
    <tr>
      <th>17</th>
      <td>salary_high</td>
      <td>-1.221986</td>
      <td>-1.198175</td>
      <td>-1.386711</td>
    </tr>
    <tr>
      <th>18</th>
      <td>salary_low</td>
      <td>0.707139</td>
      <td>0.694060</td>
      <td>0.526685</td>
    </tr>
    <tr>
      <th>19</th>
      <td>salary_medium</td>
      <td>0.176972</td>
      <td>0.165612</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>


