

```python
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
%matplotlib inline

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import (GradientBoostingClassifier, RandomForestClassifier)
from sklearn.metrics import confusion_matrix
```


```python
file = 'C:\\Users\\Abe\\Data Science Bootcamp\\Unit 3\\Potpourrie\\Credit Card\\creditcard.csv'
df = pd.read_csv(file)
df.shape
```




    (284807, 31)




```python
tree = DecisionTreeClassifier(max_depth=10, max_features=30)

X = df.drop('Class',axis=1)
y = df['Class']

tree.fit(X,y)
y_predict = tree.predict(X)
confusion_matrix(y, y_predict)
```




    array([[284315,      0],
           [    70,    422]])




```python
# Split the df in 2 groups. One for frauds and one for non frauds
frauds = df[df['Class'] == 1]
non_frauds = df[~(df['Class'] == 1)]

# Set the ratio for non frauds to frauds in the training set
non_fraud_multiplier = 1

# Create the training df
num_frauds = frauds.shape[0]
df_train = non_frauds.sample(n=num_frauds*non_fraud_multiplier).append(frauds)

# Create X and y from the new training df
X_train = df_train.drop('Class',axis=1)
y_train = df_train['Class']

# Create X and y to try and predict
df_test = df.sample(frac=.5)
X_predict = df_test.drop('Class',axis=1)
y_true = df_test['Class']

print ('Frauds: {}'.format(frauds.shape[0]))
```

    Frauds: 492
    


```python
tree = DecisionTreeClassifier(max_depth=20, max_features=30)

tree.fit(X_train,y_train)
y_predict = tree.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[127673,  14497],
           [     0,    234]])




```python
gb_tree = GradientBoostingClassifier(max_depth=20, 
                                     max_features=30,
                                     n_estimators=1000,
                                     loss='deviance')

gb_tree.fit(X_train,y_train)
y_predict = tree.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[127673,  14497],
           [     0,    234]])




```python
forest = RandomForestClassifier(max_depth=20, 
                                     max_features=30,
                                     n_estimators=50,
                                     criterion='entropy')

forest.fit(X_train,y_train)
y_predict = forest.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[137086,   5084],
           [     1,    233]])




```python
neighbors = KNeighborsClassifier(n_neighbors=10)

neighbors.fit(X_train,y_train)
y_predict = neighbors.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[103737,  38433],
           [    84,    150]])




```python
# Set the ratio for non frauds to frauds in the training set
non_fraud_multiplier = 2

# Create the training df
num_frauds = frauds.shape[0]
df_train = non_frauds.sample(n=num_frauds*non_fraud_multiplier).append(frauds)

# Create X and y from the new training df
X_train = df_train.drop('Class',axis=1)
y_train = df_train['Class']

# Create X and y to try and predict
df_test = df.sample(frac=.5)
X_predict = df_test.drop('Class',axis=1)
y_true = df_test['Class']
```


```python
tree = DecisionTreeClassifier(max_depth=20, max_features=30)

tree.fit(X_train,y_train)
y_predict = tree.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[133321,   8841],
           [     0,    242]])




```python
forest = RandomForestClassifier(max_depth=20, 
                                     max_features=30,
                                     n_estimators=50,
                                     criterion='entropy')

forest.fit(X_train,y_train)
y_predict = forest.predict(X_predict)
confusion_matrix(y_true, y_predict)
```




    array([[140736,   1426],
           [     1,    241]])




```python
# for num in np.arange(1,100,10):
#     df_train = non_frauds.sample(n=int(round(num_frauds*num,0))).append(frauds)
#     X_train = df_train.drop('Class',axis=1)
#     y_train = df_train['Class']
#     forest.fit(X_train,y_train)
#     y_predict = forest.predict(X_predict)
#     print(num)
#     print(confusion_matrix(y_true, y_predict))
```


```python
for num in np.arange(.5,.8,.02):
    frauds_train = frauds.sample(frac=num)
    df_train = non_frauds.sample(n=frauds_train.shape[0]).append(frauds_train)
    X_train = df_train.drop('Class',axis=1)
    y_train = df_train['Class']
    forest.fit(X_train,y_train)
    df_predict = df[~df.index.isin(df_train.index)]
    X_predict = df_predict.drop('Class',axis=1)
    y_true = df_predict['Class']
    y_predict = forest.predict(X_predict)
    cnf = confusion_matrix(y_true,y_predict)
    total_cnf = np.sum(cnf)
    print ('Non Fraud Ratio: {}'.format(num))
    print ('Total Non Frauds: {}'.format(df_train.shape[0] - len(frauds_train)))
    print ('Total Type I errors: {}'.format(cnf[1][0]))
    print ('Total Type II errors: {}'.format(cnf[0][1]))
    print ('--'*20)
```

    Non Fraud Ratio: 0.5
    Total Non Frauds: 246
    Total Type I errors: 24
    Total Type II errors: 16034
    ----------------------------------------
    Non Fraud Ratio: 0.52
    Total Non Frauds: 256
    Total Type I errors: 15
    Total Type II errors: 15344
    ----------------------------------------
    Non Fraud Ratio: 0.54
    Total Non Frauds: 266
    Total Type I errors: 21
    Total Type II errors: 9501
    ----------------------------------------
    Non Fraud Ratio: 0.56
    Total Non Frauds: 276
    Total Type I errors: 22
    Total Type II errors: 7320
    ----------------------------------------
    Non Fraud Ratio: 0.5800000000000001
    Total Non Frauds: 285
    Total Type I errors: 16
    Total Type II errors: 8634
    ----------------------------------------
    Non Fraud Ratio: 0.6000000000000001
    Total Non Frauds: 295
    Total Type I errors: 16
    Total Type II errors: 10643
    ----------------------------------------
    Non Fraud Ratio: 0.6200000000000001
    Total Non Frauds: 305
    Total Type I errors: 12
    Total Type II errors: 9255
    ----------------------------------------
    Non Fraud Ratio: 0.6400000000000001
    Total Non Frauds: 315
    Total Type I errors: 16
    Total Type II errors: 9787
    ----------------------------------------
    Non Fraud Ratio: 0.6600000000000001
    Total Non Frauds: 325
    Total Type I errors: 14
    Total Type II errors: 9606
    ----------------------------------------
    Non Fraud Ratio: 0.6800000000000002
    Total Non Frauds: 335
    Total Type I errors: 13
    Total Type II errors: 13652
    ----------------------------------------
    Non Fraud Ratio: 0.7000000000000002
    Total Non Frauds: 344
    Total Type I errors: 13
    Total Type II errors: 6990
    ----------------------------------------
    Non Fraud Ratio: 0.7200000000000002
    Total Non Frauds: 354
    Total Type I errors: 10
    Total Type II errors: 12589
    ----------------------------------------
    Non Fraud Ratio: 0.7400000000000002
    Total Non Frauds: 364
    Total Type I errors: 13
    Total Type II errors: 7252
    ----------------------------------------
    Non Fraud Ratio: 0.7600000000000002
    Total Non Frauds: 374
    Total Type I errors: 5
    Total Type II errors: 19897
    ----------------------------------------
    Non Fraud Ratio: 0.7800000000000002
    Total Non Frauds: 384
    Total Type I errors: 13
    Total Type II errors: 11531
    ----------------------------------------
    Non Fraud Ratio: 0.8000000000000003
    Total Non Frauds: 394
    Total Type I errors: 10
    Total Type II errors: 9499
    ----------------------------------------
    


```python
for num in np.arange(1,10,1):
    df_train = non_frauds.sample(n=frauds_train.shape[0]*num).append(frauds_train)
    X_train = df_train.drop('Class',axis=1)
    y_train = df_train['Class']
    forest.fit(X_train,y_train)
    df_predict = df[~df.index.isin(df_train.index)]
    X_predict = df_predict.drop('Class',axis=1)
    y_true = df_predict['Class']
    y_predict = forest.predict(X_predict)
    cnf = confusion_matrix(y_true,y_predict)
    total_cnf = np.sum(cnf)
    print ('Non Fraud Ratio: {}'.format(num))
    print ('Total Non Frauds: {}'.format(df_train.shape[0] - len(frauds_train)))
    print ('Total Type I errors: {}'.format(cnf[1][0]))
    print ('Total Type II errors: {}'.format(cnf[0][1]))
    print ('--'*20)
```

    Non Fraud Ratio: 1
    Total Non Frauds: 394
    Total Type I errors: 9
    Total Type II errors: 12138
    ----------------------------------------
    Non Fraud Ratio: 2
    Total Non Frauds: 788
    Total Type I errors: 11
    Total Type II errors: 3642
    ----------------------------------------
    Non Fraud Ratio: 3
    Total Non Frauds: 1182
    Total Type I errors: 12
    Total Type II errors: 2010
    ----------------------------------------
    Non Fraud Ratio: 4
    Total Non Frauds: 1576
    Total Type I errors: 12
    Total Type II errors: 1443
    ----------------------------------------
    Non Fraud Ratio: 5
    Total Non Frauds: 1970
    Total Type I errors: 12
    Total Type II errors: 1169
    ----------------------------------------
    Non Fraud Ratio: 6
    Total Non Frauds: 2364
    Total Type I errors: 12
    Total Type II errors: 800
    ----------------------------------------
    Non Fraud Ratio: 7
    Total Non Frauds: 2758
    Total Type I errors: 12
    Total Type II errors: 567
    ----------------------------------------
    Non Fraud Ratio: 8
    Total Non Frauds: 3152
    Total Type I errors: 12
    Total Type II errors: 374
    ----------------------------------------
    Non Fraud Ratio: 9
    Total Non Frauds: 3546
    Total Type I errors: 13
    Total Type II errors: 453
    ----------------------------------------
    


```python
# Split the df in 2 groups. One for frauds and one for non frauds
frauds = df[df['Class'] == 1]
non_frauds = df[~(df['Class'] == 1)]

# Use 70% of frauds to train and leave the rest for the test
frauds_train = frauds.sample(frac=.7)

# Create training set by selecting a random sample of non fraud transactions and appending selected frauds from above
df_train = non_frauds.sample(n=frauds_train.shape[0]).append(frauds_train)

# Set up training sets for X and y and fit the random forest
X_train = df_train.drop('Class',axis=1)
y_train = df_train['Class']
forest.fit(X_train,y_train)

# Select all the data left over for the model to predict
df_predict = df[~df.index.isin(df_train.index)]
X_predict = df_predict.drop('Class',axis=1)
y_true = df_predict['Class']

# Run the prediction and print out the confusion matrix
y_predict = forest.predict(X_predict)
confusion_matrix(y_true,y_predict)
```




    array([[275455,   8516],
           [     9,    139]])


